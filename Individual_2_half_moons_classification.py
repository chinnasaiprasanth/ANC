# -*- coding: utf-8 -*-
"""Individual_2_half_moons_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HrKPrEM_6d-NzC7RP04UaA_leSYCcG2V
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report
#Load dataset
path = "2halfmoonsTest.csv"

try:
    df = pd.read_csv(path)
    if not pd.api.types.is_numeric_dtype(df.iloc[:, -1]):
        df = pd.read_csv(path, header=None)
except Exception as e:
    raise RuntimeError(f"Error reading dataset: {e}")
X = df.iloc[:, :2].to_numpy(dtype=float)
y = df.iloc[:, 2].to_numpy()
if y.dtype.kind not in "iu":
    vals = pd.unique(y)
    map_ = {vals[0]: 0, vals[1]: 1}
    y = np.vectorize(map_.get)(y).astype(int)

print("Dataset loaded successfully.")
print(f"Shape: {X.shape},  Class distribution: {np.bincount(y)}\n")
#Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)
# Hyper Parameters
scaler = StandardScaler()
X_train_s = scaler.fit_transform(X_train)
X_test_s = scaler.transform(X_test)
#hyperparameters
mlp = MLPClassifier(
    hidden_layer_sizes=(16, 8),
    activation="tanh",
    solver="adam",
    learning_rate_init=0.01,
    alpha=1e-4,
    batch_size=64,
    max_iter=500,
    early_stopping=True,
    n_iter_no_change=20,
    tol=1e-5,
    random_state=42
)
print("Training model...\n")
mlp.fit(X_train_s, y_train)
#Evaluating the model
y_pred = mlp.predict(X_test_s)
# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("-----------------------------------------------------")
print(f" Test Accuracy: {accuracy:.4f}")
print("-----------------------------------------------------\n")
#Classification Report
report = classification_report(y_test, y_pred, digits=4, output_dict=False)
print("ðŸ”¹ Classification Report:\n")
print(report)
print("-----------------------------------------------------\n")
#Learning Curve
plt.figure(figsize=(6,4))
plt.plot(mlp.loss_curve_, linewidth=2)
plt.title("Learning Curve (Training Loss)")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
#Decision Boundary
pad = 0.5
h = 0.02
x_min, x_max = X[:, 0].min() - pad, X[:, 0].max() + pad
y_min, y_max = X[:, 1].min() - pad, X[:, 1].max() + pad
xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                     np.arange(y_min, y_max, h))

grid_std = scaler.transform(np.c_[xx.ravel(), yy.ravel()])
proba = mlp.predict_proba(grid_std)[:, 1].reshape(xx.shape)

plt.figure(figsize=(6,6))
CS = plt.contour(xx, yy, proba, levels=[0.5], linewidths=2, colors='k')
plt.clabel(CS, inline=True, fmt={0.5: 'p=0.5'}, fontsize=10)
plt.contourf(xx, yy, proba, levels=np.linspace(0,1,11), alpha=0.25, cmap='RdYlGn')

plt.scatter(X_train[:,0], X_train[:,1], c=y_train, marker='o', edgecolor='k', s=30, label="Train")
plt.scatter(X_test[:,0], X_test[:,1], c=y_test, marker='^', edgecolor='k', s=40, label="Test")

plt.title("Decision Boundary for Double Moon Classification")
plt.xlabel("X1")
plt.ylabel("X2")
plt.legend(loc="upper right")
plt.tight_layout()
plt.show()

#Testing phase
path_test = "2halfmoonsTest.csv"
df_test = pd.read_csv(path_test)
X_new_test = df_test.iloc[:, :2].to_numpy(dtype=float)
y_new_test_raw = df_test.iloc[:, 2].to_numpy()
#Mapping
y_new_test = np.vectorize(map_.get)(y_new_test_raw).astype(int)
class_labels = [f'Class {vals[0]}', f'Class {vals[1]}']
#Transform
X_new_test_s = scaler.transform(X_new_test)
#Predictions
y_pred_new = mlp.predict(X_new_test_s)
#Calculate confusion matrices
cm = confusion_matrix(y_new_test, y_pred_new)
cm_normalized = confusion_matrix(y_new_test, y_pred_new, normalize='true')
print("Results for Testing\n")
#Handle binary or multi-class safely
if cm.shape == (2, 2):
    TN, FP, FN, TP = cm.ravel()
    print("1) Confusion Matrix (Counts):\n", cm)
    print("\nConfusion Matrix (Normalized by True Labels - Percentages):\n", cm_normalized.round(4))
    print(f"\n2) True/False Positives/Negatives (Class {vals[1]} is Positive):")
    print(f"  True Positives (TP): {TP}")
    print(f"  False Positives (FP): {FP}")
    print(f"  False Negatives (FN): {FN}")
    print(f"  True Negatives (TN): {TN}")
else:
    print("Confusion Matrix (Counts):\n", cm)
    print("\nConfusion Matrix (Normalized by True Labels - Percentages):\n", cm_normalized.round(4))
    TN = FP = FN = TP = np.nan
    print("\n(Note: Multi-class problem detected; TP/TN/FP/FN not applicable.)")
#Overall Metrics
accuracy = accuracy_score(y_new_test, y_pred_new)
precision = precision_score(y_new_test, y_pred_new, average='binary' if cm.shape == (2, 2) else 'weighted')
recall = recall_score(y_new_test, y_pred_new, average='binary' if cm.shape == (2, 2) else 'weighted')
f1 = f1_score(y_new_test, y_pred_new, average='binary' if cm.shape == (2, 2) else 'weighted')
print("\n3) Overall Metrics:")
print(f"  Accuracy: {accuracy:.4f}")
print(f"  Precision: {precision:.4f}")
print(f"  Recall: {recall:.4f}")
print(f"  F1-score: {f1:.4f}")
print("\n")
print("Confusion Matrices(counts, normalized)")
#Matrices
fig, ax = plt.subplots(1, 2, figsize=(10, 4))
ConfusionMatrixDisplay(cm).plot(ax=ax[0], cmap="Blues", colorbar=False)
ax[0].set_title("Confusion Matrix (Counts)")
ConfusionMatrixDisplay(cm_normalized).plot(ax=ax[1], cmap="Greens", colorbar=False)
ax[1].set_title("Confusion Matrix (Normalized)")
plt.tight_layout()
plt.show()

